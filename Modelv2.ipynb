{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89af4238-b570-4596-abf4-c11aae7dd6d9",
   "metadata": {},
   "source": [
    "# Impact of variants\n",
    "\n",
    "We want to infer the effect of different variants onto the reproduction number. Given the positive tested COVID cases in a country we can infer the overall non variant specific effective spreading rate/reproduction number as described in \\cite{dehning2020inferring}. \n",
    "\n",
    "Now let $y_v$ be the number of sequenced PCR tests, which correspond to variant $v$, let $n$ be the total number of sequenced tests and $\\tau_{v,t}$ the relative fraction of the variant $v$ at timepoint $t$.\n",
    "Assuming an independent sampling of the sequenced cases, the number of samples of a given variant $v$ is given by a Binomial distribution:\n",
    "\n",
    "\\begin{align}\n",
    " y_{v,t} \\sim \\text{Bin}(\\tau_{v,t},n_t) \\quad \\forall v,t.\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91cdfa5-92b1-4994-bbab-30c10eccb1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"./covid19_inference\")\n",
    "import covid19_inference\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import covid19_inference as cov19\n",
    "from matplotlib.dates import DateFormatter,WeekdayLocator\n",
    "\n",
    "n_threads = str(1) # per process\n",
    "n_processes = 32\n",
    "os.environ[\"MKL_NUM_THREADS\"] = n_threads\n",
    "os.environ[\"OMP_NUM_THREADS\"] = n_threads\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = n_threads\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = n_threads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9b973c-fe6d-41f8-9c6e-2f6fe8fe0e5f",
   "metadata": {},
   "source": [
    "### Preprocess data\n",
    "\n",
    "Here we load the variant data for chile i.e. $y_{v,t}$ and $n_{v,t}$. The resolution for the data is weekly, starting on mondays. Additionaly we download the new confirmed cases in chile with our previous developed download utils. You can find the documentation for the dataretrieval module [here](https://covid19-inference.readthedocs.io/en/latest/doc/data_retrieval.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2e5cec-7679-4d2a-a5cd-061654629245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data variants\n",
    "variants = pd.read_excel(\"./data/Chile_Variants_Updated_without_airports.xlsx\",sheet_name=\"Variants_Count\")\n",
    "variants = variants.set_index('Lineage').T\n",
    "variants.index.name = \"Week\"\n",
    "variants.index = pd.to_datetime(variants.index + '-1', format='%V_%G-%u')\n",
    "variants = variants.iloc[0:-1]\n",
    "variant_names = [\"B.1.1\", \"B.1.1.348\", \"B.1.1.7\", \"C.37\", \"P.1\", \"unknown\"]\n",
    "\n",
    "# Load casenumbers chile and sum over weeks\n",
    "jhu = covid19_inference.data_retrieval.JHU(True)\n",
    "new_cases_obs = jhu.get_new(country=\"Chile\",data_begin=variants.index[0],data_end=variants.index[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07010af-ef52-4763-b276-fecd2cecc8b2",
   "metadata": {},
   "source": [
    "Let us take a short look into the data. We plot the total number of sampled pcr test such as the number of test which could be per variant and the reported cases in chile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f04aa5-bcb2-49f3-8f6d-d9e30b5a5f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,1,figsize=(10,8))\n",
    "\n",
    "s=0\n",
    "for c in variants.columns:\n",
    "    if c == \"N_Total\":\n",
    "        continue\n",
    "    axes[0].bar(variants.index,variants[c],width=3,label=c,bottom=s)\n",
    "    s += variants[c]\n",
    "axes[0] = covid19_inference.plot._timeseries(\n",
    "    x=variants.index,\n",
    "    y=variants[\"N_Total\"],\n",
    "    what=\"model\",\n",
    "    color=\"black\",\n",
    "    ax=axes[0],\n",
    "    label=\"Total\",\n",
    "    lw=2\n",
    ")\n",
    "axes[0].legend()\n",
    "axes[1] = covid19_inference.plot._timeseries(\n",
    "    x=new_cases_obs.index,\n",
    "    y=new_cases_obs,\n",
    "    what=\"model\",\n",
    "    color=\"tab:blue\",\n",
    "    ax=axes[1],\n",
    ")\n",
    "\n",
    "# Date layout\n",
    "date_form = DateFormatter(\"%m-%V\")\n",
    "\n",
    "# Markup\n",
    "for ax in axes:\n",
    "    ax.set_xticklabels(ax.get_xticks(), rotation=30)\n",
    "    ax.xaxis.set_major_formatter(date_form)\n",
    "    ax.xaxis.set_major_locator(WeekdayLocator(interval=1))\n",
    "    _ = ax.set_xlim(variants.index[0]-timedelta(days=2), variants.index[-1]+timedelta(days=2))\n",
    "\n",
    "fig.savefig(\"figures/overview.png\",dpi=300)\n",
    "fig.savefig(\"figures/overview.pdf\",dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965201ba-9467-468a-b675-5b22685d836c",
   "metadata": {},
   "source": [
    "### Create model\n",
    "\n",
    "We defined different models and tested which one fits the dynamics best, have a look into `run_model.py` for more informations. For now we are running the default model with dirichlet likelihood and kernelized spread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0319a258-fd49-49f3-a1a5-9a7259a4c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_model import create_model\n",
    "\n",
    "this_model = create_model(\n",
    "    likelihood=\"dirichlet\",\n",
    "    spreading_dynamics=\"kernelized_spread\",\n",
    "    variants=variants,\n",
    "    new_cases_obs=new_cases_obs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519834bd-e305-4daa-891e-250fcd68b2a1",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3a0991-4e5f-4e76-8421-57c2e5239287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3 import sample\n",
    "trace = sample(\n",
    "    model=this_model,\n",
    "    return_inferencedata=True,\n",
    "    cores=n_processes,\n",
    "    chains=4,\n",
    "    draws=400,\n",
    "    tune=1000,\n",
    "    init=\"advi+adapt_diag\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd24f014-148e-4636-aed0-43b6e9b4f8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "likelihood=\"multinomial\"\n",
    "spreading_dynamics=\"kernelized_spread\"\n",
    "\n",
    "# Save the trace (maybe we want to load it at a later point)\n",
    "with open(f\"./pickled/trace-likelihood={likelihood}-spread_method={spreading_dynamics}.pickle\", 'wb') as f:\n",
    "    pickle.dump((this_model,trace),f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8ed067-dc22-4b89-90f4-a6b00f9d8c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./pickled/Variants-likelihood=dirichlet-spread_method=kernelized_spread.pickle\", \"rb\") as f:\n",
    "    this_model, trace = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd1f352-3822-498b-8c68-ee29036a41ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(trace.sample_stats[\"lp\"].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4283dad-e583-4a74-8370-17eaf74a7a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed239d7-1da1-42f3-8a68-5cd3adb9102e",
   "metadata": {},
   "source": [
    "## Stats and plots\n",
    "\n",
    "First let's have a look if our chains converged to approx the same values. We can do that by computing the Rhat statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf862f86-1df9-41cf-9fa6-175b4a442532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "az.rhat(trace).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaeb545-9c31-4efa-9461-270b164bb679",
   "metadata": {},
   "source": [
    "Next we want to create some basic plots, given our data and the model predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63824091-5bb2-41ee-bc81-07affdaf131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeseries(trace, model, key, var=None, ax=None, **kwargs):\n",
    "    # Get data\n",
    "    if var is None:\n",
    "        var = np.array(trace.posterior[key])\n",
    "        var = var.reshape((var.shape[0]*var.shape[1],) + var.shape[2:])\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1,1,figsize=(16,8))\n",
    "\n",
    "    axes = cov19.plot._timeseries(\n",
    "        x=pd.date_range(this_model.sim_begin,this_model.sim_end),\n",
    "        y=var[:,:],\n",
    "        what=\"model\",\n",
    "        ax=ax,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    return axes\n",
    "\n",
    "fig, axes = plt.subplots(2,1,figsize=(9,5), gridspec_kw={'height_ratios': [1, 2]})\n",
    "\n",
    "# Plot new_cases\n",
    "ax = plot_timeseries(trace,this_model,\"new_cases\",ax=axes[1])\n",
    "cov19.plot._timeseries(new_cases_obs.index, new_cases_obs,what=\"data\", ax=ax)\n",
    "ax.set_ylim(0,10000)\n",
    "ax.set_ylabel(\"Daily new cases\")\n",
    "\n",
    "# Plot lambda_t\n",
    "ax = plot_timeseries(trace,this_model,\"base_lambda_t\",ax=axes[0])\n",
    "ax.set_ylabel(\"Growth rate $\\lambda_{eff}$\")\n",
    "\n",
    "\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xticklabels(ax.get_xticks(), rotation=30)\n",
    "    ax.xaxis.set_major_formatter(date_form)\n",
    "    ax.xaxis.set_major_locator(WeekdayLocator(interval=1))\n",
    "    _ = ax.set_xlim(this_model.data_begin-timedelta(days=2), this_model.data_end+timedelta(days=2))\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(\"./figures/lambda+cases.png\",dpi=300)\n",
    "fig.savefig(\"./figures/lambda+cases.pdf\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5465a4-c7d1-402e-8c2b-431263fb6dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = np.array(trace.posterior[\"Phi\"])\n",
    "var = var.reshape((var.shape[0]*var.shape[1],) + var.shape[2:])\n",
    "\n",
    "fig, axes = plt.subplots(5,1,figsize=(9,3*5))\n",
    "for v in range(len(variant_names)-1):\n",
    "    plot_timeseries(trace,this_model,var=var[:,:,v], key=\"Phi\",ax=axes[v])\n",
    "\n",
    "for a,ax in enumerate(axes):\n",
    "    ax.set_title(variant_names[a])\n",
    "    ax.set_xticklabels(ax.get_xticks(), rotation=30)\n",
    "    ax.xaxis.set_major_formatter(date_form)\n",
    "    ax.xaxis.set_major_locator(WeekdayLocator(interval=1))\n",
    "    _ = ax.set_xlim(this_model.data_begin-timedelta(days=2), this_model.data_end+timedelta(days=2))\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(\"./figures/influx.png\",dpi=300)\n",
    "fig.savefig(\"./figures/influx.pdf\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f475f67-b6f8-4f03-9904-09c083dae41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6,1,figsize=(9,3*6))\n",
    "for v, variant in enumerate(variant_names):\n",
    "    ax = cov19.plot._timeseries(\n",
    "        x=variants.index,\n",
    "        y=np.array(trace.posterior.tau_w).reshape((trace.posterior.tau_w.shape[0]*trace.posterior.tau_w.shape[1],trace.posterior.tau_w.shape[2],trace.posterior.tau_w.shape[-1],))[:,:,v],\n",
    "        what=\"model\",\n",
    "        ax=axes[v]\n",
    "    )\n",
    "    if v == 5 :\n",
    "        ax = cov19.plot._timeseries(\n",
    "            x=variants.index + timedelta(days=3.5),\n",
    "            y=(variants[\"N_Total\"]-variants[variants.columns[0:5]].sum(axis=1))/variants[\"N_Total\"],\n",
    "            what=\"data\",\n",
    "            ax=ax\n",
    "        )       \n",
    "    else:\n",
    "        ax = cov19.plot._timeseries(\n",
    "            x=variants.index + timedelta(days=3.5),\n",
    "            y=variants[variants.columns[v]]/variants[\"N_Total\"],\n",
    "            what=\"data\",\n",
    "            ax=ax\n",
    "        )\n",
    "    ax.set_title(variant)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xticklabels(ax.get_xticks(), rotation=30)\n",
    "    ax.xaxis.set_major_formatter(date_form)\n",
    "    ax.xaxis.set_major_locator(WeekdayLocator(interval=1))\n",
    "    _ = ax.set_xlim(this_model.data_begin-timedelta(days=2), this_model.data_end+timedelta(days=2))\n",
    "    \n",
    "    # \n",
    "    ax.set_ylabel(r\"$\\tau$\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"./figures/tau.png\",dpi=300)\n",
    "fig.savefig(\"./figures/tau.pdf\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f6e8f-56db-45ac-8eed-1c5e9aba8b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot as pl\n",
    "from rcParams import *\n",
    "\n",
    "colors = [\"tab:blue\",\"tab:yellow\",\"tab:green\",\"tab:red\",\"tab:purple\"]\n",
    "\n",
    "axes = pl.distribution(this_model, trace, \"f_v\", title=\"\", dist_math=\"f\")\n",
    "fig = axes[0].get_figure()\n",
    "\n",
    "for i, var in enumerate(variant_names[:-1]):\n",
    "    axes[i].set_title(var)\n",
    "    \n",
    "axes[0].set_ylabel(\"Density\")\n",
    "\n",
    "fig.savefig(\"./figures/f.png\",dpi=300)\n",
    "fig.savefig(\"./figures/f.pdf\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a298138-a98c-4426-b4f4-a88cb4dcecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(len(variant_names)-1,len(variant_names)-1,figsize=(20,20))\n",
    "for i in range(len(variant_names)-1):\n",
    "    for j in range(len(variant_names)-1):\n",
    "        x = np.array(trace.posterior.f_v[:,:,j]).flatten()\n",
    "        y = np.array(trace.posterior.f_v[:,:,i]).flatten()\n",
    "        axes[i,j].scatter(x,y, s=0.8)\n",
    "        axes[i,j].set_xlim(0,1)\n",
    "        axes[i,j].set_ylim(0,1)\n",
    "        axes[i,j].set_xlabel(variant_names[j])\n",
    "        axes[i,j].set_ylabel(variant_names[i])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab18744d-cea3-4484-a424-e4dfb8fe3243",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
